{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from transformers import pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T08:44:54.482696100Z",
     "start_time": "2023-06-01T08:44:47.652202500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "datasets_root = r\"E:/social-bot-data/datasets/Twibot-20\"\n",
    "tmp_files_root = r\"E:/social-bot-data/code/First-HGT-Detector/twibot-20/preprocess/tmp-files\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T08:53:54.658332500Z",
     "start_time": "2023-06-01T08:53:54.653333700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "node2id_list = pd.read_csv(rf\"{datasets_root}/node2id.csv\", dtype={\"node_id\": str,\"num_id\": int}) # tweets: 1-33488192, users: 33488193-33713010\n",
    "# node2id = {}\n",
    "# for row in tqdm(node2id_list.iterrows(), desc=\"Generate node2id dict.\"):\n",
    "#     node2id[row[1][\"node_id\"]] = row[1][\"num_id\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T08:54:16.389666500Z",
     "start_time": "2023-06-01T08:54:00.788095900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "node_file = \"node.json\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T08:55:11.742280700Z",
     "start_time": "2023-06-01T08:55:11.721280200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 读取用户node文件并排序"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:55:14.703035----Reading node.json...\n"
     ]
    }
   ],
   "source": [
    "print(f\"{datetime.now()}----Reading node.json...\")\n",
    "node_df = pd.read_json(rf\"{datasets_root}/{node_file}\", encoding=\"utf-8\")\n",
    "user_df = (node_df[node_df.id.str.len() > 0])[node_df.id.str.contains(\"^u\")]\n",
    "user_df = pd.merge(user_df, node2id_list, left_on=\"id\", right_on=\"node_id\", how=\"inner\")\n",
    "user_df.sort_values(\"num_id\", ascending=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T09:17:31.779273500Z",
     "start_time": "2023-06-01T08:55:14.705037500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 生成用户类别型属性的表示，n_cat_prop = 4\n",
    "四种类别型属性：\n",
    "- is_verified\n",
    "- is_protected\n",
    "- is_default_profile_image\n",
    "- has_tweets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "print(f\"{datetime.now()}----Generate category properties...\")\n",
    "is_verified_list = []\n",
    "is_protected_list = []\n",
    "is_default_profile_image_list = []\n",
    "has_tweets_list = []\n",
    "\n",
    "tqdm.pandas(desc=\"is verified list\")\n",
    "user_df[\"verified\"].progress_apply(lambda x: is_verified_list.append(1) if x == \"True \" else is_verified_list.append(0))\n",
    "tqdm.pandas(desc=\"is protected list\")\n",
    "user_df[\"protected\"].progress_apply(lambda x: is_protected_list.append(1) if x == \"True \" else is_protected_list.append(0))\n",
    "default_profile_image_url = \"http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png \"\n",
    "tqdm.pandas(desc=\"is default image url list\")\n",
    "user_df[\"profile_image_url\"].progress_apply(lambda x: is_default_profile_image_list.append(1) if x == default_profile_image_url\n",
    "else is_default_profile_image_list.append(0))\n",
    "def check_has_tweets_list(public_metrics):\n",
    "    # public_metrics = pd.DataFrame(public_metrics)\n",
    "    if public_metrics is not None and isinstance(public_metrics, dict):\n",
    "        if public_metrics[\"tweet_count\"] is not None and public_metrics[\"tweet_count\"] != 0:\n",
    "            has_tweets_list.append(1)\n",
    "        else:\n",
    "            has_tweets_list.append(0)\n",
    "    else:\n",
    "        has_tweets_list.append(0)\n",
    "tqdm.pandas(desc=\"check has tweets list\")\n",
    "user_df[\"public_metrics\"].progress_apply(check_has_tweets_list)\n",
    "\n",
    "cat_props = np.transpose([is_verified_list, is_protected_list, is_default_profile_image_list, has_tweets_list])\n",
    "cat_props_tensor = torch.tensor(cat_props, dtype=torch.float)\n",
    "torch.save(cat_props_tensor, rf\"{tmp_files_root}/cat_props_tensor.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 生成用户数量型属性的表示，n_num_prop = 5\n",
    "- followers_count\n",
    "- following_count\n",
    "- listed_count (status)\n",
    "- active_days\n",
    "- screen_name_length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 17:19:32.129809----Generate numerical properties...\n"
     ]
    },
    {
     "data": {
      "text/plain": "get numerical properties from public_metrics:   0%|          | 0/229580 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73ae25f1cc8a4fa493686cc8af963e4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "get active days from created_at:   0%|          | 0/229580 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bad26197c29b482bb1ea62bc6523d6f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "get the length of username:   0%|          | 0/229580 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc990c2a9ffd4fad9104bfc6c02a9131"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0         None\n1         None\n2         None\n3         None\n4         None\n          ... \n229575    None\n229576    None\n229577    None\n229578    None\n229579    None\nName: username, Length: 229580, dtype: object"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{datetime.now()}----Generate numerical properties...\")\n",
    "followers_count_list = []\n",
    "following_count_list = []\n",
    "listed_count_list = []\n",
    "active_days_list = []\n",
    "screen_name_length_list = []\n",
    "\n",
    "def get_public_metrics_num(public_metrics):\n",
    "    if public_metrics is not None and isinstance(public_metrics, dict):\n",
    "        if public_metrics[\"followers_count\"] is not None:\n",
    "            followers_count_list.append(int(public_metrics[\"followers_count\"]))\n",
    "        else:\n",
    "            followers_count_list.append(0)\n",
    "\n",
    "        if public_metrics[\"following_count\"] is not None:\n",
    "            following_count_list.append(int(public_metrics[\"following_count\"]))\n",
    "        else:\n",
    "            following_count_list.append(0)\n",
    "\n",
    "        if public_metrics[\"listed_count\"] is not None:\n",
    "            listed_count_list.append(int(public_metrics[\"listed_count\"]))\n",
    "        else:\n",
    "            listed_count_list.append(0)\n",
    "\n",
    "    else:\n",
    "        followers_count_list.append(0)\n",
    "        following_count_list.append(0)\n",
    "        listed_count_list.append(0)\n",
    "tqdm.pandas(desc=\"get numerical properties from public_metrics\")\n",
    "user_df[\"public_metrics\"].progress_apply(get_public_metrics_num)\n",
    "\n",
    "# created_at = pd.to_datetime(user_df[\"created_at\"], unit='s')\n",
    "init_date = datetime.strptime(\"Tue Sep 1 00:00:00 +0000 2020 \", \"%a %b %d %X %z %Y \")\n",
    "for created_at in tqdm(user_df[\"created_at\"], desc=\"get active days from created_at\"):\n",
    "    if created_at is None:\n",
    "        active_days_list.append(0)\n",
    "    else:\n",
    "        active_days_list.append((init_date - created_at).days)\n",
    "\n",
    "\n",
    "tqdm.pandas(desc=\"get the length of username\")\n",
    "user_df[\"username\"].progress_apply(lambda x: screen_name_length_list.append(len(x)) if x is not None\n",
    "else screen_name_length_list.append(0))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T09:19:35.298420500Z",
     "start_time": "2023-06-01T09:19:32.139772800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "followers_count_tensor = torch.tensor(followers_count_list).unsqueeze(dim=1)\n",
    "following_count_tensor = torch.tensor(following_count_list).unsqueeze(dim=1)\n",
    "listed_count_tensor = torch.tensor(listed_count_list).unsqueeze(dim=1)\n",
    "active_days_tensor = torch.tensor(active_days_list).unsqueeze(dim=1)\n",
    "active_days_tensor[active_days_tensor.isnan()] = 0\n",
    "screen_name_length_tensor = torch.tensor(screen_name_length_list).unsqueeze(dim=1)\n",
    "\n",
    "num_props_tensor = torch.cat([followers_count_tensor, following_count_tensor, listed_count_tensor, active_days_tensor, screen_name_length_tensor], dim=1)\n",
    "torch.save(num_props_tensor, rf\"{tmp_files_root}/raw_num_props_tensor.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T09:33:42.960278700Z",
     "start_time": "2023-06-01T09:33:42.879280400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(96)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_days_tensor.isnan()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T09:32:49.671435500Z",
     "start_time": "2023-06-01T09:32:49.662439900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107757.125, 1160911.875\n",
      "4069.03955078125, 28317.21875\n",
      "337.0955810546875, 2635.044189453125\n",
      "2335.2490234375, 1444.6646728515625\n",
      "12.263415336608887, 2.6719775199890137\n"
     ]
    }
   ],
   "source": [
    "print(rf\"{followers_count_tensor.float().mean()}, {followers_count_tensor.float().std()}\")\n",
    "print(rf\"{following_count_tensor.float().mean()}, {following_count_tensor.float().std()}\")\n",
    "print(rf\"{listed_count_tensor.float().mean()}, {listed_count_tensor.float().std()}\")\n",
    "print(rf\"{active_days_tensor.float().mean()}, {active_days_tensor.float().std()}\")\n",
    "print(rf\"{screen_name_length_tensor.float().mean()}, {screen_name_length_tensor.float().std()}\")\n",
    "num_mean_std = torch.stack([\n",
    "    torch.stack([followers_count_tensor.float().mean(), followers_count_tensor.float().std()]),\n",
    "    torch.stack([following_count_tensor.float().mean(), following_count_tensor.float().std()]),\n",
    "    torch.stack([listed_count_tensor.float().mean(), listed_count_tensor.float().std()]),\n",
    "    torch.stack([active_days_tensor.float().mean(), active_days_tensor.float().std()]),\n",
    "    torch.stack([screen_name_length_tensor.float().mean(), screen_name_length_tensor.float().std()]),\n",
    "])\n",
    "torch.save(num_mean_std, rf'{tmp_files_root}/num_mean_std.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-01T09:42:21.449322200Z",
     "start_time": "2023-06-01T09:42:21.381324500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-08 21:42:38.301399----Generate numerical properties...\n"
     ]
    },
    {
     "data": {
      "text/plain": "get numerical properties from public_metrics:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98840d5a0486420ea2b46e0b77ea1882"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "get active days from created_at:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57afd060a40e4097ad167766a28152ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "get the length of username:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba8292bb67e2422bbbcf67495af299ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"{datetime.now()}----Generate numerical properties...\")\n",
    "followers_count_list = []\n",
    "following_count_list = []\n",
    "listed_count_list = []\n",
    "active_days_list = []\n",
    "screen_name_length_list = []\n",
    "\n",
    "def get_public_metrics_num(public_metrics):\n",
    "    if public_metrics is not None and isinstance(public_metrics, dict):\n",
    "        if public_metrics[\"followers_count\"] is not None:\n",
    "            followers_count_list.append(int(public_metrics[\"followers_count\"]))\n",
    "        else:\n",
    "            followers_count_list.append(0)\n",
    "\n",
    "        if public_metrics[\"following_count\"] is not None:\n",
    "            following_count_list.append(int(public_metrics[\"following_count\"]))\n",
    "        else:\n",
    "            following_count_list.append(0)\n",
    "\n",
    "        if public_metrics[\"listed_count\"] is not None:\n",
    "            listed_count_list.append(int(public_metrics[\"listed_count\"]))\n",
    "        else:\n",
    "            listed_count_list.append(0)\n",
    "\n",
    "    else:\n",
    "        followers_count_list.append(0)\n",
    "        following_count_list.append(0)\n",
    "        listed_count_list.append(0)\n",
    "tqdm.pandas(desc=\"get numerical properties from public_metrics\")\n",
    "user_df[\"public_metrics\"].progress_apply(get_public_metrics_num)\n",
    "\n",
    "# created_at = pd.to_datetime(user_df[\"created_at\"], unit='s')\n",
    "init_date = datetime.strptime(\"Tue Sep 1 00:00:00 +0000 2020 \", \"%a %b %d %X %z %Y \")\n",
    "for created_at in tqdm(user_df[\"created_at\"], desc=\"get active days from created_at\"):\n",
    "    if created_at is None:\n",
    "        active_days_list.append(0)\n",
    "    else:\n",
    "        active_days_list.append((init_date - created_at).days)\n",
    "\n",
    "# def get_active_days(created_at):\n",
    "#     # created_at = datetime.strptime(created_at, \"\")\n",
    "#     if created_at is None:\n",
    "#         active_days_list.append(0)\n",
    "#     else:\n",
    "#         active_days_list.append(init_date - created_at)\n",
    "# tqdm.pandas(desc=\"get active days from created_at\")\n",
    "# user_df[\"created_at\"].progress_apply(get_active_days)\n",
    "\n",
    "tqdm.pandas(desc=\"get the length of username\")\n",
    "user_df[\"username\"].progress_apply(lambda x: screen_name_length_list.append(len(x)) if x is not None\n",
    "else screen_name_length_list.append(0))\n",
    "\n",
    "def fill_and_z_score(num_prop_list):\n",
    "    num_prop_df = pd.DataFrame(num_prop_list).fillna(int(0))\n",
    "    num_prop = (num_prop_df - num_prop_df.mean()) / num_prop_df.std()\n",
    "    num_prop_tensor = torch.tensor(np.array(num_prop), dtype=torch.float32)\n",
    "    return num_prop_tensor\n",
    "\n",
    "followers_count_tensor = fill_and_z_score(followers_count_list)\n",
    "following_count_tensor = fill_and_z_score(following_count_list)\n",
    "listed_count_tensor = fill_and_z_score(listed_count_list)\n",
    "active_days_tensor = fill_and_z_score(active_days_list)\n",
    "screen_name_length_tensor = fill_and_z_score(screen_name_length_list)\n",
    "\n",
    "num_props_tensor = torch.cat([followers_count_tensor, following_count_tensor, listed_count_tensor, active_days_tensor, screen_name_length_tensor], dim=1)\n",
    "torch.save(num_props_tensor, rf\"{tmp_files_root}/num_props_tensor.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 生成用户描述的表示"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "des_feature_extract = pipeline('feature-extraction', model='roberta-base', tokenizer='roberta-base', device=0, padding=True, truncation=True, max_length=50, add_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-08 20:37:39.618996----Generate description...\n"
     ]
    },
    {
     "data": {
      "text/plain": "get description tensors:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b284b38f550248958b12c82d6f11cc02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"{datetime.now()}----Generate description...\")\n",
    "des_list = []\n",
    "\n",
    "def get_des_tensor(description):\n",
    "    if description is None:\n",
    "        des_list.append(torch.zeros(768))\n",
    "    else:\n",
    "        word_tensors = torch.tensor(des_feature_extract(description))\n",
    "        each_des_tensor = torch.zeros(768)\n",
    "        for word_tensor in word_tensors[0]:\n",
    "            each_des_tensor += word_tensor\n",
    "        des_list.append(each_des_tensor)\n",
    "\n",
    "tqdm.pandas(desc=\"get description tensors\")\n",
    "user_df[\"description\"].progress_apply(get_des_tensor)\n",
    "des_tensor = torch.stack(des_list, 0)\n",
    "torch.save(des_tensor, rf\"{tmp_files_root}/des_tensor.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
